{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CuQV7SsHGIxa"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "XEtj3QrzQBuq",
    "outputId": "702a89c2-7d5f-4832-efec-ca1f0dd6c2a1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from fbprophet import Prophet\n",
    "import itertools\n",
    "\n",
    "#Split\n",
    "from sklearn.model_selection import train_test_split,TimeSeriesSplit,GridSearchCV\n",
    "#Feature selection / dimension reduction\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFECV,SelectPercentile,mutual_info_classif\n",
    "import statsmodels.api as sm\n",
    "#Performance evaluation\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P96wfo5KQBu0"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "CRLsomT2QBu0",
    "outputId": "e181c85f-23cb-410b-a868-f011a5580127"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICKET</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>NAME</th>\n",
       "      <th>UNIT_PRICEBUY</th>\n",
       "      <th>UNIT_PRICESELL</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PAYMENT</th>\n",
       "      <th>TRANSID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TOTAL_PRICEBUY</th>\n",
       "      <th>TOTAL_PRICESELL</th>\n",
       "      <th>UNIT_PRICE_MARGIN</th>\n",
       "      <th>PROFIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d9ea23a9-8a1b-41b4-b554-2bf7e96ca2d9</td>\n",
       "      <td>3.292</td>\n",
       "      <td>Pumpkin Japanese/Kent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2016-03-16 23:15:39</td>\n",
       "      <td>cash</td>\n",
       "      <td>no ID</td>\n",
       "      <td>Pumpkins</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.55108</td>\n",
       "      <td>1.99</td>\n",
       "      <td>6.55108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d9ea23a9-8a1b-41b4-b554-2bf7e96ca2d9</td>\n",
       "      <td>0.290</td>\n",
       "      <td>Orange navel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2016-03-16 23:15:39</td>\n",
       "      <td>cash</td>\n",
       "      <td>no ID</td>\n",
       "      <td>Citrus</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.86710</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.86710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f4dd518d-1fd8-4339-abc6-2c5390c20e30</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>Orange navel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2016-03-16 23:17:35</td>\n",
       "      <td>cashrefund</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citrus</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-2.99000</td>\n",
       "      <td>2.99</td>\n",
       "      <td>-2.99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa299de6-1332-48ba-bce9-de8cbb48741e</td>\n",
       "      <td>3.292</td>\n",
       "      <td>Australian Asparagus green</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2016-03-16 23:19:47</td>\n",
       "      <td>cash</td>\n",
       "      <td>no ID</td>\n",
       "      <td>Bunch Vegies</td>\n",
       "      <td>6.584</td>\n",
       "      <td>8.88840</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.30440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa299de6-1332-48ba-bce9-de8cbb48741e</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Nice Munchee 200g</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2016-03-16 23:19:47</td>\n",
       "      <td>cash</td>\n",
       "      <td>no ID</td>\n",
       "      <td>Sri Lankan Groceries</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 TICKET  UNITS                         NAME  \\\n",
       "0  d9ea23a9-8a1b-41b4-b554-2bf7e96ca2d9  3.292        Pumpkin Japanese/Kent   \n",
       "1  d9ea23a9-8a1b-41b4-b554-2bf7e96ca2d9  0.290                 Orange navel   \n",
       "2  f4dd518d-1fd8-4339-abc6-2c5390c20e30 -1.000                 Orange navel   \n",
       "3  aa299de6-1332-48ba-bce9-de8cbb48741e  3.292   Australian Asparagus green   \n",
       "4  aa299de6-1332-48ba-bce9-de8cbb48741e  1.000            Nice Munchee 200g   \n",
       "\n",
       "   UNIT_PRICEBUY  UNIT_PRICESELL                DATE     PAYMENT TRANSID  \\\n",
       "0            0.0            1.99 2016-03-16 23:15:39        cash   no ID   \n",
       "1            0.0            2.99 2016-03-16 23:15:39        cash   no ID   \n",
       "2            0.0            2.99 2016-03-16 23:17:35  cashrefund     NaN   \n",
       "3            2.0            2.70 2016-03-16 23:19:47        cash   no ID   \n",
       "4            0.9            1.50 2016-03-16 23:19:47        cash   no ID   \n",
       "\n",
       "               CATEGORY  TOTAL_PRICEBUY  TOTAL_PRICESELL  UNIT_PRICE_MARGIN  \\\n",
       "0              Pumpkins           0.000          6.55108               1.99   \n",
       "1                Citrus           0.000          0.86710               2.99   \n",
       "2                Citrus          -0.000         -2.99000               2.99   \n",
       "3          Bunch Vegies           6.584          8.88840               0.70   \n",
       "4  Sri Lankan Groceries           0.900          1.50000               0.60   \n",
       "\n",
       "    PROFIT  \n",
       "0  6.55108  \n",
       "1  0.86710  \n",
       "2 -2.99000  \n",
       "3  2.30440  \n",
       "4  0.60000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('grocery_store_data_cleaned.csv',index_col=0)\n",
    "df['DATE'] = pd.to_datetime(df['DATE']) \n",
    "df.drop(columns=['REFERENCE', 'CODE'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "DUYb6QmqQBu3",
    "outputId": "3a78b41c-f5e9-4e13-dbf2-06b9d87132ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TICKET                       object\n",
       "UNITS                       float64\n",
       "NAME                         object\n",
       "UNIT_PRICEBUY               float64\n",
       "UNIT_PRICESELL              float64\n",
       "DATE                 datetime64[ns]\n",
       "PAYMENT                      object\n",
       "TRANSID                      object\n",
       "CATEGORY                     object\n",
       "TOTAL_PRICEBUY              float64\n",
       "TOTAL_PRICESELL             float64\n",
       "UNIT_PRICE_MARGIN           float64\n",
       "PROFIT                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADd-lLRdQBu5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         16.0\n",
       "1         16.0\n",
       "2         16.0\n",
       "3         16.0\n",
       "4         16.0\n",
       "          ... \n",
       "659216    13.0\n",
       "659217    13.0\n",
       "659218    13.0\n",
       "659219    13.0\n",
       "659220    13.0\n",
       "Name: Day, Length: 659221, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['yyyymmdd'] = [d.date() for d in df['DATE']]\n",
    "df['Month'] = [d.date().month for d in df['DATE']]\n",
    "df['Day'] = [d.date().day for d in df['DATE']]\n",
    "df['Month'].astype(float)\n",
    "df['Day'].astype(float)\n",
    "#df_daily = df.groupby(pd.to_datetime(df.yyyymmdd).dt.date).agg({'Day':'first','Month':'first', 'TOTAL_PRICEBUY': 'sum', 'TOTAL_PRICESELL':'sum'}).reset_index()\n",
    "\n",
    "#df_daily = df_daily.set_index(pd.DatetimeIndex(df_daily['yyyymmdd']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "7y-OGJ13QBu8",
    "outputId": "fd7ab4c1-ce93-41e3-c334-f2311bf4a1f0"
   },
   "outputs": [],
   "source": [
    "#df_daily['Daily Profit'] = df_daily['TOTAL_PRICESELL'] - df_daily['TOTAL_PRICEBUY']\n",
    "#df_daily['Cumulative Sales'] = df_daily['TOTAL_PRICESELL'].cumsum()\n",
    "\n",
    "#df_daily['Forward Daily Profit'] = df_daily['Daily Profit'].shift(-1)\n",
    "\n",
    "#df_daily = df_daily.dropna()\n",
    "#df_daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "V6u20apmRvye",
    "outputId": "131a8a6c-907b-48dc-df45-b650806cb731"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pumpkins', 'Citrus', 'Bunch Vegies', 'Sri Lankan Groceries',\n",
       "       'Other Vegies', 'Veggies', 'Cabbages', 'Asian Vegies',\n",
       "       'Stonefruits', 'Onions', 'carrots', 'Tropical Fruits', 'Melons',\n",
       "       'Grapes', 'Potatoes', 'Tomatoes', 'Cucumbers', 'Bananas', 'Apples',\n",
       "       'Pears', 'Chillies', 'Other Fruits', 'Nuts', 'Herbs', 'Mushrooms',\n",
       "       'Lettuces', 'capsicum', 'Root Vegies', 'Multi buy', 'Eggs',\n",
       "       'Avocadoes', 'Berries', 'Cut Veggies', 'Flowers',\n",
       "       'Olympian Products', 'Groceries-Dry Goods', 'Cut Fruits',\n",
       "       'Kalamata olives', 'coconut Products', 'Fruits', 'trutaste',\n",
       "       'Pastas', 'markdown bag'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['catstr'] = df['CATEGORY'].astype(str)\n",
    "df['catstr'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 949
    },
    "colab_type": "code",
    "id": "PY419xboeJa_",
    "outputId": "7ddefd5d-eaca-4401-d8e5-6906ad912b34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICKET</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>NAME</th>\n",
       "      <th>UNIT_PRICEBUY</th>\n",
       "      <th>UNIT_PRICESELL</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PAYMENT</th>\n",
       "      <th>TRANSID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TOTAL_PRICEBUY</th>\n",
       "      <th>TOTAL_PRICESELL</th>\n",
       "      <th>UNIT_PRICE_MARGIN</th>\n",
       "      <th>PROFIT</th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>catstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d9ea23a9-8a1b-41b4-b554-2bf7e96ca2d9</td>\n",
       "      <td>3.292</td>\n",
       "      <td>Pumpkin Japanese/Kent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2016-03-16 23:15:39</td>\n",
       "      <td>cash</td>\n",
       "      <td>no ID</td>\n",
       "      <td>Pumpkins</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.55108</td>\n",
       "      <td>1.99</td>\n",
       "      <td>6.55108</td>\n",
       "      <td>2016-03-16</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>Pumpkins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d9ea23a9-8a1b-41b4-b554-2bf7e96ca2d9</td>\n",
       "      <td>0.290</td>\n",
       "      <td>Orange navel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2016-03-16 23:15:39</td>\n",
       "      <td>cash</td>\n",
       "      <td>no ID</td>\n",
       "      <td>Citrus</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.86710</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.86710</td>\n",
       "      <td>2016-03-16</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>Citrus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f4dd518d-1fd8-4339-abc6-2c5390c20e30</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>Orange navel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2016-03-16 23:17:35</td>\n",
       "      <td>cashrefund</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citrus</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-2.99000</td>\n",
       "      <td>2.99</td>\n",
       "      <td>-2.99000</td>\n",
       "      <td>2016-03-16</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>Citrus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa299de6-1332-48ba-bce9-de8cbb48741e</td>\n",
       "      <td>3.292</td>\n",
       "      <td>Australian Asparagus green</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2016-03-16 23:19:47</td>\n",
       "      <td>cash</td>\n",
       "      <td>no ID</td>\n",
       "      <td>Bunch Vegies</td>\n",
       "      <td>6.584</td>\n",
       "      <td>8.88840</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.30440</td>\n",
       "      <td>2016-03-16</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>Bunch Vegies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa299de6-1332-48ba-bce9-de8cbb48741e</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Nice Munchee 200g</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2016-03-16 23:19:47</td>\n",
       "      <td>cash</td>\n",
       "      <td>no ID</td>\n",
       "      <td>Sri Lankan Groceries</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>2016-03-16</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>Sri Lankan Groceries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659216</th>\n",
       "      <td>5cb041e2-1976-45b4-ba06-7779d6893156</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Curry powder250g kandyan</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.99</td>\n",
       "      <td>2019-10-13 17:41:45</td>\n",
       "      <td>magcard</td>\n",
       "      <td>904210501806</td>\n",
       "      <td>Sri Lankan Groceries</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.99000</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.99000</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>Sri Lankan Groceries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659217</th>\n",
       "      <td>5cb041e2-1976-45b4-ba06-7779d6893156</td>\n",
       "      <td>1.042</td>\n",
       "      <td>Banana Cavendish</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2019-10-13 17:41:45</td>\n",
       "      <td>magcard</td>\n",
       "      <td>904210501806</td>\n",
       "      <td>Bananas</td>\n",
       "      <td>2.084</td>\n",
       "      <td>2.07358</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01042</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>Bananas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659218</th>\n",
       "      <td>5cb041e2-1976-45b4-ba06-7779d6893156</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Tomatoes Cherry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2019-10-13 17:41:45</td>\n",
       "      <td>magcard</td>\n",
       "      <td>904210501806</td>\n",
       "      <td>Tomatoes</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>Tomatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659219</th>\n",
       "      <td>8e1e8d7c-9247-44bc-b50e-dd01acb68974</td>\n",
       "      <td>0.382</td>\n",
       "      <td>Onion brown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2019-10-13 17:43:20</td>\n",
       "      <td>cash</td>\n",
       "      <td>no ID</td>\n",
       "      <td>Onions</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.76018</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.76018</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>Onions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659220</th>\n",
       "      <td>8e1e8d7c-9247-44bc-b50e-dd01acb68974</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Eggs 700g</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2019-10-13 17:43:20</td>\n",
       "      <td>cash</td>\n",
       "      <td>no ID</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>5.400</td>\n",
       "      <td>6.40000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>659221 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      TICKET  UNITS  \\\n",
       "0       d9ea23a9-8a1b-41b4-b554-2bf7e96ca2d9  3.292   \n",
       "1       d9ea23a9-8a1b-41b4-b554-2bf7e96ca2d9  0.290   \n",
       "2       f4dd518d-1fd8-4339-abc6-2c5390c20e30 -1.000   \n",
       "3       aa299de6-1332-48ba-bce9-de8cbb48741e  3.292   \n",
       "4       aa299de6-1332-48ba-bce9-de8cbb48741e  1.000   \n",
       "...                                      ...    ...   \n",
       "659216  5cb041e2-1976-45b4-ba06-7779d6893156  1.000   \n",
       "659217  5cb041e2-1976-45b4-ba06-7779d6893156  1.042   \n",
       "659218  5cb041e2-1976-45b4-ba06-7779d6893156  1.000   \n",
       "659219  8e1e8d7c-9247-44bc-b50e-dd01acb68974  0.382   \n",
       "659220  8e1e8d7c-9247-44bc-b50e-dd01acb68974  2.000   \n",
       "\n",
       "                               NAME  UNIT_PRICEBUY  UNIT_PRICESELL  \\\n",
       "0             Pumpkin Japanese/Kent            0.0            1.99   \n",
       "1                      Orange navel            0.0            2.99   \n",
       "2                      Orange navel            0.0            2.99   \n",
       "3        Australian Asparagus green            2.0            2.70   \n",
       "4                 Nice Munchee 200g            0.9            1.50   \n",
       "...                             ...            ...             ...   \n",
       "659216     Curry powder250g kandyan            2.0            3.99   \n",
       "659217             Banana Cavendish            2.0            1.99   \n",
       "659218              Tomatoes Cherry            0.0            3.00   \n",
       "659219                  Onion brown            0.0            1.99   \n",
       "659220                    Eggs 700g            2.7            3.20   \n",
       "\n",
       "                      DATE     PAYMENT       TRANSID              CATEGORY  \\\n",
       "0      2016-03-16 23:15:39        cash         no ID              Pumpkins   \n",
       "1      2016-03-16 23:15:39        cash         no ID                Citrus   \n",
       "2      2016-03-16 23:17:35  cashrefund           NaN                Citrus   \n",
       "3      2016-03-16 23:19:47        cash         no ID          Bunch Vegies   \n",
       "4      2016-03-16 23:19:47        cash         no ID  Sri Lankan Groceries   \n",
       "...                    ...         ...           ...                   ...   \n",
       "659216 2019-10-13 17:41:45     magcard  904210501806  Sri Lankan Groceries   \n",
       "659217 2019-10-13 17:41:45     magcard  904210501806               Bananas   \n",
       "659218 2019-10-13 17:41:45     magcard  904210501806              Tomatoes   \n",
       "659219 2019-10-13 17:43:20        cash         no ID                Onions   \n",
       "659220 2019-10-13 17:43:20        cash         no ID                  Eggs   \n",
       "\n",
       "        TOTAL_PRICEBUY  TOTAL_PRICESELL  UNIT_PRICE_MARGIN   PROFIT  \\\n",
       "0                0.000          6.55108               1.99  6.55108   \n",
       "1                0.000          0.86710               2.99  0.86710   \n",
       "2               -0.000         -2.99000               2.99 -2.99000   \n",
       "3                6.584          8.88840               0.70  2.30440   \n",
       "4                0.900          1.50000               0.60  0.60000   \n",
       "...                ...              ...                ...      ...   \n",
       "659216           2.000          3.99000               1.99  1.99000   \n",
       "659217           2.084          2.07358              -0.01 -0.01042   \n",
       "659218           0.000          3.00000               3.00  3.00000   \n",
       "659219           0.000          0.76018               1.99  0.76018   \n",
       "659220           5.400          6.40000               0.50  1.00000   \n",
       "\n",
       "          yyyymmdd  Month  Day                catstr  \n",
       "0       2016-03-16      3   16              Pumpkins  \n",
       "1       2016-03-16      3   16                Citrus  \n",
       "2       2016-03-16      3   16                Citrus  \n",
       "3       2016-03-16      3   16          Bunch Vegies  \n",
       "4       2016-03-16      3   16  Sri Lankan Groceries  \n",
       "...            ...    ...  ...                   ...  \n",
       "659216  2019-10-13     10   13  Sri Lankan Groceries  \n",
       "659217  2019-10-13     10   13               Bananas  \n",
       "659218  2019-10-13     10   13              Tomatoes  \n",
       "659219  2019-10-13     10   13                Onions  \n",
       "659220  2019-10-13     10   13                  Eggs  \n",
       "\n",
       "[659221 rows x 17 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "l3o1Miswa2Ny",
    "outputId": "f199776d-cf42-4080-c925-a0bc27b2caf5"
   },
   "outputs": [],
   "source": [
    "#df[df['CATEGORY'] == 'Citrus'].groupby(df['yyyymmdd']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O7d419OLV0lA"
   },
   "source": [
    "## Linear and Time Series Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lJPAwTERxjt"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge,SGDRegressor,ElasticNet,Lars,Lasso,BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor,RandomForestRegressor\n",
    "\n",
    "#dictionary of regression models \n",
    "regressors = {}\n",
    "regressors.update({\"Linear\":LinearRegression()})\n",
    "regressors.update({\"Ridge\":Ridge()})\n",
    "regressors.update({\"SGD\":SGDRegressor()})\n",
    "regressors.update({\"ElasticNet\":ElasticNet()})\n",
    "regressors.update({\"Lars\":Lars()})\n",
    "regressors.update({\"Lasso\":Lasso()})\n",
    "regressors.update({\"BayesianRidge\":BayesianRidge()})\n",
    "regressors.update({\"DecisionTreeRegressor\":DecisionTreeRegressor()})\n",
    "regressors.update({\"ExtraTree\":ExtraTreeRegressor()})\n",
    "regressors.update({\"Bagging\":BaggingRegressor()})\n",
    "regressors.update({\"RandomForest\":RandomForestRegressor()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9qRM5nOV4xx"
   },
   "source": [
    "## Stationarity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-QqovlvV5M3"
   },
   "outputs": [],
   "source": [
    "categories = df.CATEGORY.unique()\n",
    "categories\n",
    "\n",
    "def create_single_series(data, col_name, cat, freq='NA'):\n",
    "  #Function changes the frequency of the time series based on the and selectes a \n",
    "  #certain column with the variable cat.\n",
    "    if freq == 'NA':\n",
    "        freq_data = data.loc[data.CATEGORY == cat,f'{col_name.upper()}']\n",
    "        return freq_data\n",
    "    else:\n",
    "        freq_data = data.loc[data.CATEGORY == cat,f'{col_name.upper()}']\n",
    "        freq_data = freq_data.resample(freq).sum()\n",
    "        return freq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G2AZXGKdWQ70"
   },
   "outputs": [],
   "source": [
    "# Augmented Dickey-Fuller Test (ADF Test)/unit root test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "def adf_test(ts, cat, signif=0.05):\n",
    "    dftest = adfuller(ts, autolag='AIC')\n",
    "    adf = pd.Series(dftest[0:4], index=['Test Statistic','p-value','# Lags','# Observations'])\n",
    "    for key,value in dftest[4].items():\n",
    "        adf['Critical Value (%s)'%key] = value\n",
    "    \n",
    "    p = adf['p-value']\n",
    "    if p <= signif:\n",
    "        print(f\"{cat} Series is Stationary\")\n",
    "        return True\n",
    "    else:\n",
    "        print('')\n",
    "        print(adf)\n",
    "        print(f\"{cat} Series is Non-Stationary\")\n",
    "        print('')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "tTCnpYUiWRkN",
    "outputId": "80be52f0-9975-4648-89d9-9ff2c8e399d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pumpkins Series is Stationary\n",
      "\n",
      "Test Statistic            -2.039310\n",
      "p-value                    0.269607\n",
      "# Lags                    20.000000\n",
      "# Observations          1286.000000\n",
      "Critical Value (1%)       -3.435445\n",
      "Critical Value (5%)       -2.863790\n",
      "Critical Value (10%)      -2.567968\n",
      "dtype: float64\n",
      "Citrus Series is Non-Stationary\n",
      "\n",
      "Bunch Vegies Series is Stationary\n",
      "Sri Lankan Groceries Series is Stationary\n",
      "Other Vegies Series is Stationary\n",
      "Veggies Series is Stationary\n",
      "Cabbages Series is Stationary\n",
      "Asian Vegies Series is Stationary\n",
      "\n",
      "Test Statistic            -2.393966\n",
      "p-value                    0.143447\n",
      "# Lags                    22.000000\n",
      "# Observations          1157.000000\n",
      "Critical Value (1%)       -3.436015\n",
      "Critical Value (5%)       -2.864041\n",
      "Critical Value (10%)      -2.568102\n",
      "dtype: float64\n",
      "Stonefruits Series is Non-Stationary\n",
      "\n",
      "Onions Series is Stationary\n",
      "carrots Series is Stationary\n",
      "Tropical Fruits Series is Stationary\n",
      "Melons Series is Stationary\n",
      "\n",
      "Test Statistic            -2.486847\n",
      "p-value                    0.118708\n",
      "# Lags                    22.000000\n",
      "# Observations          1275.000000\n",
      "Critical Value (1%)       -3.435489\n",
      "Critical Value (5%)       -2.863810\n",
      "Critical Value (10%)      -2.567978\n",
      "dtype: float64\n",
      "Grapes Series is Non-Stationary\n",
      "\n",
      "Potatoes Series is Stationary\n",
      "Tomatoes Series is Stationary\n",
      "Cucumbers Series is Stationary\n",
      "\n",
      "Test Statistic            -2.480776\n",
      "p-value                    0.120222\n",
      "# Lags                    20.000000\n",
      "# Observations          1285.000000\n",
      "Critical Value (1%)       -3.435449\n",
      "Critical Value (5%)       -2.863792\n",
      "Critical Value (10%)      -2.567969\n",
      "dtype: float64\n",
      "Bananas Series is Non-Stationary\n",
      "\n",
      "\n",
      "Test Statistic            -2.642862\n",
      "p-value                    0.084458\n",
      "# Lags                    20.000000\n",
      "# Observations          1285.000000\n",
      "Critical Value (1%)       -3.435449\n",
      "Critical Value (5%)       -2.863792\n",
      "Critical Value (10%)      -2.567969\n",
      "dtype: float64\n",
      "Apples Series is Non-Stationary\n",
      "\n",
      "Pears Series is Stationary\n",
      "Chillies Series is Stationary\n",
      "Other Fruits Series is Stationary\n",
      "Nuts Series is Stationary\n",
      "Herbs Series is Stationary\n",
      "Mushrooms Series is Stationary\n",
      "\n",
      "Test Statistic            -2.837583\n",
      "p-value                    0.053103\n",
      "# Lags                    23.000000\n",
      "# Observations          1282.000000\n",
      "Critical Value (1%)       -3.435461\n",
      "Critical Value (5%)       -2.863797\n",
      "Critical Value (10%)      -2.567972\n",
      "dtype: float64\n",
      "Lettuces Series is Non-Stationary\n",
      "\n",
      "capsicum Series is Stationary\n",
      "Root Vegies Series is Stationary\n",
      "Multi buy Series is Stationary\n",
      "Eggs Series is Stationary\n",
      "Avocadoes Series is Stationary\n",
      "Berries Series is Stationary\n",
      "Cut Veggies Series is Stationary\n",
      "\n",
      "Test Statistic            -1.662752\n",
      "p-value                    0.450399\n",
      "# Lags                    20.000000\n",
      "# Observations          1279.000000\n",
      "Critical Value (1%)       -3.435473\n",
      "Critical Value (5%)       -2.863802\n",
      "Critical Value (10%)      -2.567975\n",
      "dtype: float64\n",
      "Flowers Series is Non-Stationary\n",
      "\n",
      "Olympian Products Series is Stationary\n",
      "Groceries-Dry Goods Series is Stationary\n",
      "Cut Fruits Series is Stationary\n",
      "Kalamata olives Series is Stationary\n",
      "coconut Products Series is Stationary\n",
      "Fruits Series is Stationary\n",
      "trutaste Series is Stationary\n",
      "Pastas Series is Stationary\n",
      "markdown bag Series is Stationary\n"
     ]
    }
   ],
   "source": [
    "stationary_series = []\n",
    "temp_df = df.set_index('DATE')\n",
    "for cate in categories:\n",
    "    series = create_single_series(temp_df,col_name='TOTAL_PRICESELL',cat=cate, freq='1D')\n",
    "    test_res = adf_test(series, cate)\n",
    "    if test_res:\n",
    "        stationary_series.append(cate)\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE\n",
       "2016-09-28     1.0\n",
       "2016-09-29    22.0\n",
       "2016-09-30    17.0\n",
       "2016-10-01    29.0\n",
       "2016-10-02    33.0\n",
       "              ... \n",
       "2019-10-09     3.0\n",
       "2019-10-10     5.0\n",
       "2019-10-11     6.0\n",
       "2019-10-12    15.0\n",
       "2019-10-13     2.0\n",
       "Freq: D, Name: TOTAL_PRICESELL, Length: 1111, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvJ4MhOhWaok"
   },
   "source": [
    "## Helper Functions for testing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "ae-4DgWS4GyQ",
    "outputId": "50faa381-9193-4a49-eace-a1c2fc1ef184"
   },
   "outputs": [],
   "source": [
    "def ML_record_performance(df_results, model_name, y_train_hat, y_train,y_test_hat,y_test,pred_future):\n",
    "    #Takes in df_results,y_hat and true y for both in and out of sample\n",
    "    #Record training and testing MSE\n",
    "    in_sample_mse = metrics.mean_squared_error(y_train_hat, y_train)\n",
    "    out_of_sample_mse = metrics.mean_squared_error(y_test_hat, y_test)\n",
    "#     print(in_sample_mse)\n",
    "#     print(out_of_sample_mse)\n",
    "    #Return updated df_results\n",
    "    \n",
    "    df_results.loc[model_name] = [in_sample_mse, out_of_sample_mse,pred_future[-1]]\n",
    "\n",
    "def ML_model_pipeline(df_results, category, model_name, model_object, X_train_raw, X_test_raw, y_train, y_test,last_row):\n",
    "    #Takes in sklearn's model object, and train & test data\n",
    "    # Model object passed in by the dictionary (value store is passed in)\n",
    "    model_curr = model_object\n",
    "    #USE RFECV function to find the best subset of features for the model to get X_train\n",
    "    # Using model_object as estimator\n",
    "    try: \n",
    "        rfecv = RFECV(estimator=model_curr, step=1, cv=5, scoring='neg_mean_squared_error')   \n",
    "        rfecv = rfecv.fit(X_train_raw, y_train)\n",
    "\n",
    "        #Transform X_test based on feature selection \n",
    "        X_train_raw = X_train_raw[X_train_raw.columns[rfecv.support_]]\n",
    "        X_test_raw = X_test_raw[X_test_raw.columns[rfecv.support_]]\n",
    "        last_row = last_row[last_row.columns[rfecv.support_]]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #Fit train data\n",
    "    model_curr.fit(X_train_raw, y_train)\n",
    "    #Predict train data\n",
    "    train_predicted = model_curr.predict(X_train_raw)\n",
    "    #Predict testing data\n",
    "    test_predicted = model_curr.predict(X_test_raw)\n",
    "    \n",
    "    #predict 3 month in future\n",
    "    pred_future = model_curr.predict(last_row)\n",
    "    #record in sample MSE and out of sample MSE by calling the record_performance function\n",
    "    ML_record_performance(df_results, model_name, train_predicted, y_train, test_predicted, y_test,pred_future)\n",
    "    # Recording selected features for given model \n",
    "    dict_selected_features[category][model_name] = X_train_raw.columns\n",
    "\n",
    "def TS_record_performance(df_results, model_name, y_train_hat, y_train,y_test_hat,y_test,pred_future):\n",
    "    #TOO DOO RAAAHIIIIIIMM\n",
    "\n",
    "    #Takes in df_results,y_hat and true y for both in and out of sample\n",
    "    #Record training and testing MSE\n",
    "\n",
    "    ##########################################################################\n",
    "    in_sample_mse = metrics.mean_squared_error(y_train_hat, y_train)\n",
    "    out_of_sample_mse = metrics.mean_squared_error(y_test_hat, y_test)\n",
    "    #Return updated df_results\n",
    "    ###########################################################################\n",
    "#     print(in_sample_mse)\n",
    "#     print(out_of_sample_mse)\n",
    "#     #Return updated df_results\n",
    "    pred_future = np.asarray(pred_future, dtype=np.float64)\n",
    "    df_results.loc[model_name] = [in_sample_mse, out_of_sample_mse,pred_future[-1]]\n",
    "\n",
    "\n",
    "def TS_model_pipeline(df_results, category, model_name,y_train, y_test,additional_steps) :\n",
    "\n",
    "    #creating series\n",
    "    #X_train_series = X_train_raw['TOTAL_PRICESELL']\n",
    "    #X_test_series = X_test_raw['TOTAL_PRICESELL']\n",
    "    #Parameter Optimization\n",
    "    p = d = q = range(0, 2)\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "    seasonal_pdq = [(x[0], x[1], x[2], 3) for x in list(itertools.product(p, d, q))] \n",
    "    temp_min = 50000\n",
    "    ord_param=(0,0,0)\n",
    "    s_param=(0,0,0,0)\n",
    "    for param in pdq:\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "            try:\n",
    "                mod = sm.tsa.statespace.SARIMAX(y_train,\n",
    "                                                    order=param,\n",
    "                                                    seasonal_order=param_seasonal,\n",
    "                                                    enforce_stationarity=False,\n",
    "                                                    enforce_invertibility=False)\n",
    "                results = mod.fit()\n",
    "                if results.aic < temp_min:\n",
    "                    temp_min = results.aic\n",
    "                    ord_param = param\n",
    "                    s_param = param_seasonal\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    #Fit train data\n",
    "    mod = sm.tsa.statespace.SARIMAX(y_train,\n",
    "                                  order=ord_param,\n",
    "                                  seasonal_order=s_param,\n",
    "                                  enforce_stationarity=False,\n",
    "                                  enforce_invertibility=False)\n",
    "    results = mod.fit()\n",
    "    #Predict train data\n",
    "    train_predicted = results.get_prediction(start=y_train.index[0], end=y_train.index[-1], dynamic=False)\n",
    "    #Predict testing data\n",
    "    test_predicted = results.get_forecast(steps=len(y_test))\n",
    "    \n",
    "    pred_future = results.get_forecast(steps=additional_steps)\n",
    "    \n",
    "    \n",
    "    #record in sample MSE and out of sample MSE by calling the reord_performance function\n",
    "    TS_record_performance(df_results, model_name, train_predicted.predicted_mean, y_train, test_predicted.predicted_mean, y_test, pred_future.predicted_mean)\n",
    "\n",
    "    # Recording selected features for given model \n",
    "    dict_selected_features[category][model_name] = 'TOTAL_PRICESELL_rolling_sum_91'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gays3onQW7F3"
   },
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_asb9O50dYmP",
    "outputId": "e9baa886-97d0-460f-cf2f-a3f3f5c129bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now working on  Pumpkins\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Pumpkins  is  ElasticNet\n",
      "Now working on  Bunch Vegies\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Bunch Vegies  is  Linear\n",
      "Now working on  Sri Lankan Groceries\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Sri Lankan Groceries  is  Lasso\n",
      "Now working on  Other Vegies\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Other Vegies  is  RandomForest\n",
      "Now working on  Veggies\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Veggies  is  SARIMA\n",
      "Now working on  Cabbages\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Cabbages  is  SARIMA\n",
      "Now working on  Asian Vegies\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Asian Vegies  is  SARIMA\n",
      "Now working on  Onions\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Onions  is  Lars\n",
      "Now working on  carrots\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  carrots  is  RandomForest\n",
      "Now working on  Tropical Fruits\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Tropical Fruits  is  SGD\n",
      "Now working on  Melons\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Melons  is  RandomForest\n",
      "Now working on  Potatoes\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Potatoes  is  ExtraTree\n",
      "Now working on  Tomatoes\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Tomatoes  is  SARIMA\n",
      "Now working on  Cucumbers\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Cucumbers  is  ElasticNet\n",
      "Now working on  Pears\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Pears  is  DecisionTreeRegressor\n",
      "Now working on  Chillies\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Chillies  is  ElasticNet\n",
      "Now working on  Other Fruits\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Other Fruits  is  DecisionTreeRegressor\n",
      "Now working on  Nuts\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Nuts  is  Linear\n",
      "Now working on  Herbs\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Herbs  is  BayesianRidge\n",
      "Now working on  Mushrooms\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Mushrooms  is  ExtraTree\n",
      "Now working on  capsicum\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  capsicum  is  SARIMA\n",
      "Now working on  Root Vegies\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Root Vegies  is  Bagging\n",
      "Now working on  Multi buy\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Multi buy  is  Ridge\n",
      "Now working on  Eggs\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Eggs  is  SGD\n",
      "Now working on  Avocadoes\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Avocadoes  is  Lars\n",
      "Now working on  Berries\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Berries  is  Linear\n",
      "Now working on  Cut Veggies\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n",
      "--------Best model for  Cut Veggies  is  Linear\n",
      "Now working on  Olympian Products\n",
      "----Now working on SARIMA\n",
      "----Now working on  Linear\n",
      "----Now working on  Ridge\n",
      "----Now working on  SGD\n",
      "----Now working on  ElasticNet\n",
      "----Now working on  Lars\n",
      "----Now working on  Lasso\n",
      "----Now working on  BayesianRidge\n",
      "----Now working on  DecisionTreeRegressor\n",
      "----Now working on  ExtraTree\n",
      "----Now working on  Bagging\n",
      "----Now working on  RandomForest\n"
     ]
    }
   ],
   "source": [
    "dict_selected_features = {}\n",
    "\n",
    "list_of_models = list(regressors.keys())\n",
    "list_of_models.append(\"SARIMA\")\n",
    "predicted_sales =  pd.DataFrame(index = stationary_series,columns = [\"Predicted 3 Month Sales\"])\n",
    "\n",
    "\n",
    "for category in stationary_series:\n",
    "    print(\"Now working on \", category)\n",
    "    \n",
    "    dict_selected_features[category] = {}\n",
    "    df_results = pd.DataFrame(index = list_of_models,columns = ['In-Sample MSE', 'Out-of-Sample MSE',\"Predicted 3 Month Sales\"])\n",
    "\n",
    "    df_curr = df[df['CATEGORY'] == category]\n",
    "    df_curr = df_curr.groupby(pd.to_datetime(df.yyyymmdd).dt.date).agg({'Day':'first','Month':'first', 'TOTAL_PRICEBUY': 'sum', 'TOTAL_PRICESELL':'sum'}).reset_index()\n",
    "    df_curr = df_curr.set_index(pd.DatetimeIndex(df_curr['yyyymmdd']))\n",
    "    \n",
    "    ##FEATURE FUCKING ENGINEERING BABY\n",
    "    df_curr['PROFIT'] = df_curr['TOTAL_PRICESELL'] - df_curr['TOTAL_PRICEBUY']\n",
    "\n",
    "    #Lookback periods\n",
    "    lookback = [7,14,21,91]#1 week, 2 week, 3 week, 3 months\n",
    "    #Compute key statistics for each lookback period\n",
    "    features = ['PROFIT','TOTAL_PRICEBUY','TOTAL_PRICESELL']\n",
    "    \n",
    "    for col in features:\n",
    "        for i in lookback:\n",
    "            #         df_curr[col+'_ret_' + str(i)] = df[col+\"_cumsum\"]/df[col+\"_cumsum\"].shift(i)-1\n",
    "            df_curr[col+\"_rolling_sum_\"+ str(i)] = df_curr[col].rolling(i).sum()\n",
    "            df_curr[col+'_rolling_mean_' + str(i)] = df_curr[col].rolling(i).mean()\n",
    "            df_curr[col+'_rolling_stdev_' + str(i)] = df_curr[col].rolling(i).std()\n",
    "\n",
    "    #y values\n",
    "    target = 'TOTAL_PRICESELL_rolling_sum_91'\n",
    "    df_curr[target] = df_curr[target].shift(-91) #3 months into the future (365/4)\n",
    "    \n",
    "    \n",
    "    df_curr.drop(columns=['yyyymmdd'], inplace=True)\n",
    "    last_row = df_curr.tail(1).loc[:, df_curr.columns != target]\n",
    "    df_curr = df_curr.dropna()\n",
    "    \n",
    "    \n",
    "    X = df_curr.loc[:, df_curr.columns != target]\n",
    "    y = df_curr[target]\n",
    "    if X.shape[0] == 0:\n",
    "        print(\"Skipped \",category,\" due to size 0 after trimming\")\n",
    "    else:\n",
    "        X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        additional_steps = int((last_row.index - df_curr.index[-1]).days[0])\n",
    "        print('----Now working on SARIMA')\n",
    "        TS_model_pipeline(df_results, category, \"SARIMA\", y_train, y_test,additional_steps)\n",
    "\n",
    "        for model_name, model_object in regressors.items():\n",
    "            print(\"----Now working on \", model_name)\n",
    "            ML_model_pipeline(df_results, category, model_name, model_object, X_train_raw, X_test_raw, y_train, y_test,last_row)\n",
    "\n",
    "        best_model_name = pd.to_numeric(df_results['Out-of-Sample MSE']).idxmin()\n",
    "\n",
    "        print(\"--------Best model for \",category,\" is \",best_model_name)\n",
    "        predicted_sales[\"Predicted 3 Month Sales\"][category] = df_results['Predicted 3 Month Sales'][best_model_name]\n",
    "    \n",
    "    fileName = category + \".csv\"\n",
    "    df_results.to_csv(fileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RH1NkEl_TXI9"
   },
   "outputs": [],
   "source": [
    "predicted_sales.sort_values(by=[\"Predicted 3 Month Sales\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BjLGbWSvt8Ag"
   },
   "outputs": [],
   "source": [
    "predicted_sales.to_csv(\"predicted_sales.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import matplotlib as mpl\n",
    "# sns.set_style('whitegrid')\n",
    "mpl.rcParams['axes.labelsize'] = 14\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "plt.rc('figure',figsize=(16,12))\n",
    "plt.rc('font',size=13)\n",
    "plt.rc('lines', lw=0.80, mew=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Nw2RIN9XIKej",
    "outputId": "fa9a9108-bc66-40af-f801-893123fcb0cf"
   },
   "outputs": [],
   "source": [
    "feat_scores = pd.to_numeric((predicted_sales['Predicted 3 Month Sales']))         \n",
    "top_feat = feat_scores.nlargest(10)\n",
    "top_feat.plot(kind='barh')\n",
    "plt.title(\"Top 10 Predicted Sales\")\n",
    "plt.savefig('top.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7-EkJqEH7U4"
   },
   "outputs": [],
   "source": [
    "\n",
    "feat_scores = pd.to_numeric((predicted_sales['Predicted 3 Month Sales']))         \n",
    "top_feat = feat_scores.nsmallest(10)\n",
    "top_feat.plot(kind='barh')\n",
    "plt.title(\"Lowest 10 Predicted Sales\")\n",
    "plt.savefig('low.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbjEewKmHeI2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "6QzbfLvCIAl5",
    "outputId": "ed2e417b-6eec-4f82-a5b9-fa2037a49710"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nR0MXMsmIHUf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of time_series_decomposition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
